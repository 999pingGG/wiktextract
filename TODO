
# XXX cf "word" translations under "watchword" and "proverb" - what kind of
# link/ext is this?  {{trans-see|watchword}}

# XXX add parsing chinese pronunciations, see 傻瓜 https://en.wiktionary.org/wiki/%E5%82%BB%E7%93%9C#Chinese

# XXX implement parsing {{ja-see-kango|xxx}} specially, see むひ

# XXX check use of sense numbers in translations (check "eagle"/English)

# XXX in Coordinate terms, handle bullet point titles like Previous:, Next:
# (see "ten", both Coordinate terms and Synonyms)

# XXX change pronunciation parsing to traverse LIST and then expand individual
# items (warn about non-list content), similar to already done for linkage

# XXX parse etymology; take "compound", "affix", prefix" templates and save
# as dictionaries under "compound"

# XXX parse "alter" tags; see where they are used (they seem to be alternate
# forms)

# XXX parse "enum" tags (args: lang, prev, next, value)

# XXX check use of ja-r and ja-r/args templates in linkage and capture
# hira, kana

Parse Phonetic hangeul in Pronunciation section (see 死/Korean)

# XXX make sure parenthesized parts in the middle of form-of descriptions
# in gloss are handled properly.  Check "vise" (Swedish verb).

# XXX check translation hub

# XXX check allowed head templates, see template_allowed_pos_map

# XXX test that config.capture_* options work

# XXX distinguish non-gloss definition from gloss, see e.g. βούλομαι

# XXX check "unsupported tag component 'E' warning / in "word"

# XXX parse "id" field in {{trans-top|id=...}} (and overall parse wikidata ids)

# XXX implement support for image files in {{mul-symbol|...}} head, e.g.,
# Unsupported titles/Cifrão

# XXX Some declination/conjugation template arguments contain templates, e.g.
# mi/Serbo-Croatian (pronoun).  Should probably strip these templates, but
# not strip as aggressively as normal clean_value() does.  HTML tags and links
# should be stripped.

# XXX review inserting error/warning tags in words that trigger errors/warnings

XXX {\tt Appendix:Variations of "a"} pages?  However Latn-script
template seems to know a ton about these so maybe look at it.

# XXX clean up extra calls to map_with in form_descriptions.py; now handled
# in decode_tags()

# XXX parse "Derived characters" section.  It may contain multiple
# space-separated characters in same list item.

# XXX extract Readings section (e.g., Kanji characters)

# XXX handle qualifiers starting with "of " specially.  They are quite common
# for adjectives, describing what the adjective can characterize

# XXX parse "object of a preposition", "indirect object of a verb",
# "(direct object of a verb)", "(as the object of a preposition)",
# "(as the direct object of a verbal noun)",
# in parenthesis at the end of gloss

# XXX parse [+infinitive = XXX], [+accusative = XXX], etc in gloss
# see e.g. βούλομαι.  These come from {{+obj|...}}, might also just parse
# the template.

# XXX parse "construed with XXX" from sense qualifiers or capture "construed with" template

# XXX add warnings about / in places where we try to parse tags

# XXX how about gloss "The name of the letter X",
# "The name of the Latin-script letter X"
# "The name of the Latin-script digraph XY",
# "The name of the Hebrew-script letter X"
# "The name of the Greek-script letter X"
# "The name of the Devanagari letter X"
# "The name of the Cyrillic-script letter X"
# "The name of the Assamese character X"
# "The name of the Arabic-script letter X"
# "The XXX letter of the YYY alphabet..."
# the same without The
# Letter of the X syllabary, transcribed as X
# Letter of the Tagbanwa abugida, transcribed as syllable X
# Letter of the X script, transcribed as X
# Letter of the X alphabet ...
# Letter of the X alphabet: ...

# XXX how about gloss "Compound of XXX and YYY".  There are 100k of these.
#   - sometimes followed by semicolon and notes or "-" and notes
#   - sometimes Compound of gerund of XXX and YYY
#   - sometimes Compound of imperative (noi form) of XXX and YYY
#   - sometimes Compound of imperative (tu form) of XXX and YYY
#   - sometimes Compound of imperative (vo form) of XXX and YYY
#   - sometimes Compound of imperative (voi form) of XXX and YYY
#   - sometimes Compound of imperative of XXX and YYY
#   - sometimes Compound of indicative present of XXX and YYY
#   - sometimes Compound of masculine plural past participle of XXX and YYY
#   - sometimes Compound of past participle of XXX and YYY
#   - sometimes Compound of present indicative of XXX and YYY
#   - sometimes Compound of past participle of XXX and YYY
#   - sometimes Compound of plural past participle of XXX and YYY
#   - sometimes Compound of second-person singular imperative of XXX and YYY
#   - sometimes Compound of in base a and YYY
#   - sometimes Compound of in merito a and YYY
#   - sometimes Compound of in mezzo a and YYY
#   - sometimes Compound of in seguito a and YYY
#   - sometimes Compound of nel bel mezzo di and YYY
#   - sometimes Compound of per mezzo di and YYY
#   - sometimes Compound of per opera di and YYY
#   - sometimes Compound of XXX, YYY and ZZZ
#   - sometimes Compound of XXX + YYY
#   - sometimes Compound of the gerund of XXX and YYY
#   - sometimes Compound of the imperfect XXX and the pronoun YYY
#   - sometimes Compound of the infinitive XXX and the pronoun YYY

# XXX handle "Wiktionary appendix of terms relating to animals" ("animal")

# XXX check "Kanji characters outside the ..."

# XXX recognize "See also X" from end of gloss and move to a "See also" section

# Look at "prenderle"/Italian - two heads under same part-of-speech.  Second
# head ends up inside first gloss.

# XXX handle (classifier XXX) at beginning of gloss; also (classifier: XXX)
# and (classifiers: XXX, XXX, XXX)
# E.g.: 煙囪
# Also: 筷子 (this also seems to have synonym problems!)

# XXX parse redirects, create alt_of

# XXX Handle "; also YYY" syntax in initialisms (see AA/Proper name)

# XXX parse {{zh-see|XXX}} - see 共青团

# XXX is the Usage notes section parseable in any useful way?  E.g., there
# is a template {{cmn-toneless-note}}.  Are there other templates that would
# be useful and common enough to parse, e.g., into tags?

# XXX capture topic hierarchy from Category pages in Wiktionary
#   - Module:category tree/topic cat/data/* (except /documentation)
#   - beware, at least .../Places contains real code besides data
#   - Load place types from Module:place/data
#   - also: Module:place/shared-data/tables
#   - also: Module:place/shared-data
# May be best to actually load these modules as Lua code or to even run a
# specific Lua module to dump the data.

# XXX search for Template: from all glosses, search for &amp; from all glosses

# XXX in parse_head_tags(), should create multiple forms if
# node["$"].get("tags") contains multiple sets of tags (e.g., cut/English/Verb)

# Check te/Spanish/pron, See also section (warning, has unexpected format)

# Check alt_of with "." remaining.  Find them all to a separate list
# and analyze.

# When alt-of has English translation (often in quotes), try to capture it
# (helpful for disambiguation!).  E.g., 假設/Vietnamese

# XXX wikipedia, Wikispecies links.  See "permit"/English/Noun

# XXX handle inflection of with multiple forms; see aquamarine/German/Adjective
#   - This is tricky.  This case is generated by {{de-adj form of|...}} and there
#     is no knowing how many such templates there are.  We may need to treat
#     the sub-entries as either equal senses or sub-senses.
#   - we should also fix treatment of *# etc; we need to just expand to
#     HTML, then split there (at line start), and then clean.  Otherwise we
#     risk breaking glosses that contain * or # (e.g., math formulas).

# XXX handle <ruby> specially in clean or perhaps already earler, see
# e.g. 無比 (Japanese)
  - should capture ruby
  - should capture roman

# XXX There are way too many <noinclude> not propersy closed warnings
# forom Chinese, e.g., 內 - find out what causes these, and either fix or
# ignore

# Parse readings subsection in Japanese kanji characters, see 內
#  - these are apparently pronunciations, but not IPA
#  - perhaps these might be parsed as forms with "reading" tag and tag
#    for the type of reading?

# Korean kanji seem to have Phonetic hangeul in pronunciation sections, see 內

# XXX chinese glyphs, see 內
#  - I'm getting dial-syn page does not exist in synonyms, but Wiktionary
#    shows a big list of synonyms

# XXX Some Chinese words have weird /wiki.local/ in sounds, see: 屋
#  - also in pronunciations, several IPAs are captured, but they are not
#    annotated with dialect information
#  - this page also has dial-syn warning in synonyms (also noted elsewhere)
#  - in Japanese compounds, roman transliterations incorrectly go into tags
#  - in Japanese, does it make sense to have most senses annotated with "kanji"?

Collect etymology information

# XXX handle "XXX/derived terms" pages

/derived terms (seem to be referenced with {{section link|...}}

數/derived terms
仔/derived terms
人/derived terms
龍/derived terms
馬/derived terms

# In htmlgen, create links from gloss, at minimum when whole gloss matches
# a word form in English (or maybe gloss as an alternative?)

htmlgen: Improve sense/word lists
  - more even sizes of sublists (use intervals when appropriate)
  - group kanji etc by radical + strokes
htmlgen: include word prefixes in breadcrumbs
htmlgen: Implement better list page generation

htmlgen: form-of (and alt-of) links in generated html should look at
canonical form in addition to word - now many items with accents are
not properly linked

htmlgen: strange Categories non-disambiguated in: https://kaikki.org/dictionary/English/meaning/v/vo/volva.html#volva-noun

htmlgen: compound-of field of sense not displayed in generated html

htmlgen: implement support for redirects

htmlgen: render audio-ipa for audios

htmlgen: make search faster on slow links (split to deeper prefixes if large)

htmlgen: when looking for linkage references, also check canonical
word form

Word entires may be generated from entries like "Thesaurus:ar:make happy" that
are in a wrong language.  Check if they are referenced from somewhere and
maybe restrict generation to entries that are actually referenced.

Check extraction of pronunciations and their romanizations in 공중/Korean

Consider caching template expansions in an LRU cache.  Make sure
template arguments that can be accessed from Lua are considered
properly.  Cache must be reset per-page.  (Does DISPLAYPAGE break this?)

Check * at the end of some derived forms in wort/English/Noun (e.g., dropwort*)
  - it actually is in the original wikitext and is used as a reference symbol,
    with explanation at the end of the table
  - should probably just remove the *
  - check if there are other similar reference symbols and how common they are

Apparently the following is not parsed correctly:
{{ws sense|any of enclosing symbols "(", ")", "[", "]", "{", "}" etc.}}

Recognize and parse {{zh-dial|...}} in linkage, e.g., 鼎/Chinese
  - Variety = language (these are more like translation than synonyms)
  - Location = tags, parenthesized part separate tag?
  - Words may have Notes references, which may need to be parsed as senses
    (not clear how common they are with other words)

{{syn|...}} not properly handled in nested glosses, see frons/Latin
sense "the forehead, brow, front", search for "vultus"

In translations, should process {{trans-see|...}} (cf. "abound with",
the only translations are with {{trans-see|...}})

ख/Translingual/Letter: DEBUG: unhandled parenthesized prefix: (Devanagari script letters) अ,‎ आ,‎ इ,‎ ई,‎ उ,‎ ऊ,‎ ऋ,‎ ए,‎ ऐ,‎ ओ,‎ औ,‎ अं,‎ अः,‎ अँ,‎ क,‎ ख,‎ ग,‎ घ,‎ ङ,‎ च,‎ छ,‎ ज,‎ झ,‎ ञ,‎ ट,‎ ठ,‎ ड,‎ ढ,‎ ण,‎ त,‎ थ,‎ द,‎ ध,‎ न,‎ प,‎ फ,‎ ब,‎ भ,‎ म,‎ य,‎ र,‎ ल,‎ व,‎ श,‎ ष,‎ स,‎ ह,‎ त्र,‎ ज्ञ,‎ क्ष,‎ क़,‎ ख़,‎ ग़,‎ ज़,‎ झ़,‎ ड़,‎ ढ़,‎ ष़ <nowiki>[</nowiki><nowiki>]</nowiki> at ['ख']
- is nowiki broken in templates?  Perhaps core.py:_template_to_body should
  call preprocess_text for the template body?

Check:
can/English/Verb: ERROR: no language name in translation item: : ... at ['can']
can/English/Verb: ERROR: no language name in translation item: : -bil- (tr) (verbal infix) at ['can']

smiley/Dutch/Noun: ERROR: LUA error in #invoke ('nl-headword', 'show', 'nouns') parent ('Template:nl-noun', {1: 'm', 2: '-s', 3: 'smileytje'}) at ['smiley', 'nl-noun', '#invoke']
[string "Module:gender and number"]:170: attempt to index a nil value (field 'spec')
stack traceback:
        [string "Module:gender and number"]:170: in function 'Module:gender and number.format_genders'
        [string "Module:headword"]:330: in upvalue 'format_genders'
        [string "Module:headword"]:511: in upvalue 'show_headword_line'
        [string "Module:headword"]:658: in function 'Module:headword.full_headword'
        [string "Module:nl-headword"]:35: in function 'Module:nl-headword.show'
        [C]: in function 'xpcall'
        [string "_sandbox_phase2"]:214: in function <[string "_sandbox_phase2"]:136>

Make sure rtl (right-to-left) and ltr markers are properly inserted
and matched in words (including translations and linkages), even when
splitting them.

Implement better parsing of compound_of base.  There are over 135k
compound_of entries in Wiktionary, so this is common enough to care
about.

Use something similar to tr "note" detection in linkages (e.g.,
pitää/Finnish search +).  Also, the parenthesized tags in Derived
terms as subheadings are currently not handled.

Check strange and incorrectly processed category link in
अधिगच्छति/Sanskrit (I suspect this may be coding error in Wiktionary,
looks like the category has a nested link)

Fix parsing linkages for letters in scripts, see P/English/Number
  - longer sequences of characters
  - P/Latvian "burti:" prefix handled incorrectly (should be separate linkage)
  - P/Vietnamese first word incorrectly split (never split before semicolon)
  - P/Vietnamese multi-char names inside parentheses handled incorrectly
    (replace parentheses by comma? colon by comma?)
Handle " / " as a separator in linkages; see be/Faroese/related
(Latin-script letter names)

have/English/Translations/"to possess"/Arabic: have "- you have" at end of tr;
similarly "- I have"

language/English has weird IPAs coming from qualifier (see
/ae/ raising)

Add more sanity checks:
  - number of words extracted for a few major languages (English, Korean, Zulu)
  - number of extraction errors of various kinds
  - number of translations extracted for major languages
  - number of linkages extracted for major languages
  - number of suspicious linkages
  - number of suspicious alt-of/form-of
  - number of alt-of
  - number of form-of
  - number of IPAs
  - number of forms
  - number of inflection templates
  - number of non-disambiguated translations
  - number of non-disambiguated linkages
  - number of senses with tags
  - number of senses with topics

お茶/Japanese/Verb:
  - "ocha suru" as romanization, "suru" should not be there
  - "intransitive suru" gets into end of canonical form
  - stem and past are not correctly parsed
  - related terms are not correctly parsed - English goes into alt

滿/Vietnamese: head not handled correctly, fix

Handle and remove right-to-left mark (and left-to-right mark) from titles,
forms, translations, linkages.  Add tag "right-to-left" where they were
present.  (Or should we keep the marks but still add tag?)

Fix support for DISPLAYTITLE - sets page default display title, which
would be useful.  Maybe extract too?  Note that this may prevent
caching templates/Lua calls.

Handle synonym-of; see "Number 11"

Review translations that contain comma

Check "class II noun" and similar "note" in translations, cf. form desc,
define required tags/mappings

Consider improving romanization recognition in translation by
capturing strings inside <span class="tr [Latn]"> and never
interpreting such strings as English.  This would would probably hook
into clean_node().

Review handling of 0x200e (left-to-right mark) and 0x200f
(right-to-left mark) in linkages.  Also, what if only one is present?
cf. test_script5 in test_linkages.py

B/Portugues list of characters is broken
Finish writing tests for character lists

Synonyms are not collected from nested senses.  See cat/English/Noun
sense 1/1 "A domesticated species..."

See tree/English/Hyponyms: Category:en:Trees

Move hieroglyph conversion to postprocessing

婬/Japanese/Kanji/Definitions has a table that is not correctly handled,
and is being parsed as head form.

Handle (* Poetic.) and (** Antiquanted.) and */** at end of form, e.g.
камень/Russian

Check topics in word head, cf. अंगूठा/Hindi, which has (anatomy) in head
Fix parsing "wait on hand, foot and finger"/English head parsing
(comma splits related forms).  Maybe similar magic character kludge as we do
for linkages? No, that won't work here... maybe just merge standalone
parts that are comma-separated parts of the title to the previous entry
with a comma (as a pre-processing step after splitting?).  Inflection though
might be in any of the parts, but I think usually the first.
Also: "wait on someone hand, foot and finger"/English.
Ah, similar bug in alt-of/inflection-of parsing.

Implement special case in parsing word head for paren desc:
"на (na) accusative, by"; see помножать/Russian

Something wrong in parsing آتي/Arabic "coming"

Fix parsing "or" separated alternatives in canonical forms?  Or is it broken?

Finish datautils.py:split_slashes and use it for translations/linkages/heads
  - warn when clearly ambigious
  - add more tests in test_utils.py

Which language should be used in translation when langcode and language in the
entry differ?  This is particularly an issue for Chinese.  Or should we treat
the second-level entries (e.g., Mandarin) as tags?

Change clean_value in clean.py to receive ctx.  Add "hieroglyphs" tag
if the string contains <hiero> tag.  (Or maybe this needs to go in
clean_node in page.py?  Or maybe these two should be merged?)

Why is extraction suddenly very slow?  Is it because topics are no
longer copied?

FIX exponential regexp in core.py:_encode (in wikitextprocessor). jet/Czech

"dog" - gets Lua error, probable error in parsing (could be related to
temporarily rolled back exponential regexp patch)
